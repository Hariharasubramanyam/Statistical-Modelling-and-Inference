# Bayesian Regression


Measuring the joint probability of t, X, w, q using the probability (likelihood) of t given X, w, q times the probabilty of X (which is assumed as independent of w and q) and the prior probability of p(w, q).

**Question:** What does it mean the prior is the probability of p(w, q)?

The posterior is given as the probability of w and q given t and X (**Question:** How is X different from t?)

Slide 8 of bayesian-regression
**Questions:**

1. Why is the probability of w equal to the normal distribution of w given mu and D?
2. Why are mu and D fixed? (Isn't this by definition?)
3. p(x(1:n)) is irrelevant because? They are used to derive features and then disposed?
