
### 2. In terms of deliverables, you should report how many individuals you removed from the dataset, you should explain what was your preferred model, on which grounds you chose it and interpret all estimated coefficients in the model.

```{r}
library('foreign', echo=FALSE)
heightft <- read.fwf("wfw90.dat", widths=c(143,1))$V2
heightin <- read.fwf("wfw90.dat", widths=c(145,1))$V2
height <- heightft * 12 + heightin
weight <- read.fwf("wfw90.dat", widths=c(146,3))$V2
earn <- read.fwf("wfw90.dat", widths=c(202,6))$V2
gender <- read.fwf("wfw90.dat", widths=c(218,1))$V2
data <- matrix(c(earn, height, weight, gender),
  nrow = length(gender),
  ncol = 4)
data <- as.data.frame(data)
dimnames(data)[[2]] <- c('earn', 'height', 'weight', 'gender')

# Fix unusually coded data
data$male <- ifelse(data$gender == 2, 1, 0)

# Remove individuals with no salary data
data <- na.omit(data)
# Remove individuals with bad weight data
data <- subset(data, weight < quantile(weight, probs = c(0.98))[[1]])
data <- subset(data, height < quantile(height, probs = c(0.98))[[1]])

# Dumb regression
dumbmodel <- lm(formula = data$earn ~ data$height)

# Q: What transformation should you perform in order to interpret the intercept
# from this model as average earnings for people with average height?
#
# A: Create a new variable, avgheightdiff, which is the
# difference btw height average height.
#
# The intercept of the new model is the value when avgheightdiff = 0, so the
# average salary for someone of average height.
#
data$avgheightdiff <- data$height - mean(data$height)
data$avgweightdiff <- data$weight - mean(data$weight)

# Improved significance of intercept
# Intercept went from -26035 in the dumb model to 19858
avghtmodel <- lm(formula = data$earn ~ data$avgheightdiff)
avgwtmodel <- lm(formula = data$earn ~ data$avgweightdiff)
combinedmodel <- lm(formula = data$earn ~ data$avgheightdiff + data$avgweightdiff)

# Q: Fit some regression models with the goal of predicting earnings from some
# combination of sex, height, and weight. Be sure to try various
# transformations and interactions that might make sense. Choose your
# preferred model and justify.
#
# Ideas:
# Use z-scores

# Use interaction of gender and weight or height or both?
# Want to use interaction to determine how slope might be different across subgroups
women <- subset(data, male == 1)
men <- subset(data, male == 0)

# Both models have low significance in the avgheightdiff coeff
wmodel <- lm(formula = women$earn ~ women$avgheightdiff)
mmodel <- lm(formula = men$earn ~ men$avgheightdiff)
# So even though it appears the have very different slopes (for male it's negative?)
# We do not want to include interaction of height and gender

# Try the same thing with weight
# Lower but still significant results
wmodel <- lm(formula = women$earn ~ women$avgweightdiff))
mmodel <- lm(formula = men$earn ~ men$avgweightdiff))

# This will include a new coefficient which captures the effect of both height and being male
interactionmodel <- lm(formula = data$earn ~ data$avgheightdiff + data$avgweightdiff + data$avgweightdiff:data$male)

# Lower significance of avgheightdiff coefficient

# Remove intercept (To remove this use either ‘y ~ x - 1’ or ‘y ~ 0 + x’)
combinedavgmodel <- lm(formula = data$earn ~ 0 +
  data$avgheightdiff +
  data$avgweightdiff +
  data$male +
  data$avgweightdiff:data$male)
summary(combinedavgmodel)

# Now there is no significance of the height coefficient

# Now I want to do the whole thing over again with z-scores
# Did try standardizing earn as well but felt model was more interpretable using nominal earnings
#
# Also ignoring intercept from now on as pretty evident its uninterpretable
#
z.data.weight <- (data$weight - mean(data$weight)) / (2*sd(data$weight))
z.data.height <- (data$height - mean(data$height)) / (2*sd(data$height))
z.data.earn   <- data$earn
z.data.male   <- data$male

# Dumb model
(dumbmodel <- lm(formula = z.data.earn ~ 0 + z.data.height))

htmodel <- lm(formula = z.data.earn ~ 0 + z.data.height)
wtmodel <- lm(formula = z.data.earn ~ 0 + z.data.weight)
combined <- lm(formula = z.data.earn ~ 0 + z.data.height + z.data.weight)

combinedzmodel <- lm(formula = z.data.earn ~ 0 +
  z.data.height +
  z.data.weight +
  z.data.male +
  z.data.weight:z.data.male)

summary(combinedzmodel)
```

*How many individuals were removed from the dataset?*

651 individuals were removed because salary data was not available (NA), 29 individuals were removed for having bad weight data, 58 individuals were removed for having bad height data.

*What is your preferred model and why?*

```{r}
combinedavgmodel <- lm(formula = data$earn ~ 0 +
  data$avgheightdiff +
  data$avgweightdiff +
  data$male +
  data$avgweightdiff:data$male)
```

Either of the models, using z-score or difference from average seem like the best fit of the data. Interpreting the coefficients is seems more human-readable in the average model fit.

*On which grounds do you chose it?*

I chose it because all the coefficients have a high significance level, suggesting they each contribute towards the outcome variable (earnings). 

*What are the interpretations of the coefficients?*

```{r}
Call:
lm(formula = data$earn ~ 0 + data$avgheightdiff + data$avgweightdiff + 
    data$male + data$avgweightdiff:data$male)

Coefficients:
                             Estimate Std. Error t value Pr(>|t|)    
data$avgheightdiff             700.46     189.77   3.691 0.000233 ***
data$avgweightdiff             581.36      35.89  16.196  < 2e-16 ***
data$male                    14765.55     904.70  16.321  < 2e-16 ***
data$avgweightdiff:data$male  -639.64      45.42 -14.084  < 2e-16 ***
```

Being one inch taller increases salary \$700, if you are female, being one pound heavier increases earnings \$581.36, being male increases earnings by \$14765.55, while if you are male, being one pound heavier decreases earnings \$58.28.

### 3. Inference for the ratio of parameters: a (hypothetical) study compares the costs and effectiveness of two different medical treatments.


```{r}
library(metRology)

cost.diff.mean <- 600
cost.diff.se <- 400
cost.diff.dof <- 50

effectiveness.diff.mean <- 3.0
effectiveness.diff.se <- 1.0
effectiveness.diff.dof <- 100

nsims <- 1000
draws <- matrix(0, nrow=nsims, ncol=2)
dimnames(draws)[[2]] <- c('cost.draw', 'effectiveness.draw')

# (a) Create 1000 simulation draws of the cost difference and the effectiveness difference, and make a scatterplot of these draws.
for (idx in 1:nsims) {
  cost.draw <- rt.scaled(n=1, mean=cost.diff.mean, sd=cost.diff.se, df=cost.diff.dof)
  effectiveness.draw <- rt.scaled(n=1, mean=effectiveness.diff.mean, sd=effectiveness.diff.se, df=effectiveness.diff.dof)
  draws[idx,'cost.draw'] <- cost.draw
  draws[idx,'effectiveness.draw'] <- effectiveness.draw
}
plot(draws)

# (b) Use simulation to come up with an estimate, 50% interval, and 95% interval for the incremental cost-effectiveness ratio.
probs <- c(0.025,0.25,0.75,0.975)

cost.intervals <- quantile(draws[,'cost.draw'], probs = probs)
cost.quants.twentyfive <- cost.intervals['25%'][[1]]
cost.quants.seventyfive <- cost.intervals['75%'][[1]]
cost.quants.twoptfive <- cost.intervals['2.5%'][[1]]
cost.quants.ninetysevenptfive <- cost.intervals['97.5%'][[1]]

effectiveness.intervals <- quantile(draws[,'effectiveness.draw'], probs = probs)
effectiveness.quants.twentyfive <- effectiveness.intervals['25%'][[1]]
effectiveness.quants.seventyfive <- effectiveness.intervals['75%'][[1]]
effectiveness.quants.twoptfive <- effectiveness.intervals['2.5%'][[1]]
effectiveness.quants.ninetysevenptfive <- effectiveness.intervals['97.5%'][[1]]

(ratio.seventyfive <- cost.quants.seventyfive / effectiveness.quants.seventyfive)
(ratio.twentyfive <- cost.quants.twentyfive / effectiveness.quants.twentyfive)
# 50% interval for cost-effectiveness ratio => 140.9322 to 236.7033

(ratio.ninetysevenptfive <- cost.quants.ninetysevenptfive / effectiveness.quants.ninetysevenptfive)
(ratio.twoptfive <- cost.quants.twoptfive / effectiveness.quants.twoptfive)
# 95% interval for cost-effectiveness ratio => -180.3731 to 265.1693

# (c) Repeat this problem, changing the standard error on the difference in effectiveness to 2.0.
effectiveness.diff.se <- 2.0

nsims <- 1000
draws <- matrix(0, nrow=nsims, ncol=2)
dimnames(draws)[[2]] <- c('cost.draw', 'effectiveness.draw')

for (idx in 1:nsims) {
  cost.draw <- rt.scaled(n=1, mean=cost.diff.mean, sd=cost.diff.se, df=cost.diff.dof)
  effectiveness.draw <- rt.scaled(n=1, mean=effectiveness.diff.mean, sd=effectiveness.diff.se, df=effectiveness.diff.dof)
  draws[idx,'cost.draw'] <- cost.draw
  draws[idx,'effectiveness.draw'] <- effectiveness.draw
}
plot(draws)

# 50% interval for cost-effectiveness ratio => 191.9712 to 207.1226
# 95% interval for cost-effectiveness ratio => 188.1102 to 203.0376
```


### 4. Replicate step by step the analysis done in Section 7.3 of Gelman and Hill on predicting electoral results.

```{r}
# Model
# election outcome = constant + democratic_share + incumbency
#   1) constant - self-explanatory
#   2) democratic_share - continuous
#   3) incumbency - categorical: 1 for dem incumbent, -1 for rep incumbent, 0 for open
#
setwd("~/Box Sync/abarciausksas/myfiles/Statistical Modelling and Inference/week4")
library(foreign)

data90 <- read.table('1990.asc')
data88 <- read.table('1988.asc')
data86 <- read.table('1986.asc')
vote <- cbind(data86[,3:5], data88[,3:5], data90[,3:5])
years <- seq(86,90,2)
cnames <- list()
for (y in 1:length(years)) {
  cnames <- append(cnames, lapply(c('incumbency', 'demvote', 'repvote'), paste0, '.', years[y]))
}
cnames <- unlist(cnames)
colnames(vote) <- cnames

vote <- subset(vote, vote[,'demvote.88'] > 0)
vote <- subset(vote, vote[,'demvote.86'] > 0)
vote.88 <- vote[,'demvote.88'] / (vote[,'demvote.88'] + vote[,'repvote.88'])
vote.86 <- vote[,'demvote.86'] / (vote[,'demvote.86'] + vote[,'repvote.86'])

fit.88 <- lm(vote.88 ~ vote.86 + vote[,'incumbency.88'])

# creating a new matrix of predictors, Xtilde
n.tilde <- length(vote.88)
X.tilde <- cbind(rep(1, n.tilde), vote.88, vote[,'incumbency.90'])

# We then simulate 1000 times
library(arm)
n.sims <- 1000
sim.88 <- sim(fit.88, n.sims)
y.tilde <- array(NA, c(n.sims, n.tilde))
for (s in 1:n.sims) {
  y.tilde[s,] <- rnorm(n.tilde, X.tilde %*% slot(sim.88, name='coef')[s,], slot(sim.88, name='sigma')[s])
}
dems.tilde <- rowSums(y.tilde > .5)

Pred.88 <- function (X.pred, lm.fit) {
  n.pred <- dim(X.pred)[1]
  sim.88 <- sim(lm.fit, 1)
  y.pred <- rnorm(n.pred, X.pred %*% t(slot(sim.88, name='coef')), slot(sim.88, name='sigma'))
  return (y.pred)
}

y.tilde <- replicate (1000, Pred.88(X.tilde, fit.88))
```
