---
title: Group 8 - GLM Exercises
date: November 10, 2015
output: pdf_document
---

## 1. A density that belongs in the one-parameter exponential family has the following (canonical) representation:

$p(z) = ...$

where $\theta$ is called the natural parameter, and c and h are functions whose exact form depends on the particular density. For many members of this family, q > 0, is a further unknown parameter, often called a precision parameter.

## 1. The following densities belong to the exponential family. Identify $\theta$, $q$ and an appropriate $c(\theta)$, for each of them (take into account that for some z might be a transformation of $t$):

### Normal

[ADD ME]

### Bernoulli

$t \textasciitilde Bern(n,p) = p^{z} (1-p)^{1-z}$

$exp \Bigg\{ log(p^{z}) + log((1-p)^{1-z}) \Bigg\}$

$exp \Bigg\{ z log(p) + (1-z) log(1-p) \Bigg\}$

$exp \Bigg\{ z log(p) + log(1-p) - z log(1-p) \Bigg\}$

$exp \Bigg\{ z log(\frac{p}{1-p}) + log(1-p) \Bigg\}$

**Result:**

$\theta = log(\frac{p}{1-p})$

$q = 1$

$c(\theta) = -log(1-p)$

### Binomial

$t \textasciitilde Bin(n,p) = {n \choose k} p^{k} (1-p)^{n-k}$

$exp \Bigg\{ log({n \choose k }) + log(p^{k}) + log((1-p)^{n-k}) \Bigg\}$

$exp \Bigg\{ log({n \choose k }) + k log(p) + (n-k) log(1-p) \Bigg\}$

$exp \Bigg\{ log({n \choose k }) + k log(\frac{p}{1-p}) + n log(1-p) \Bigg\}$

$exp \Bigg\{ n \Bigg[\frac{k}{n} log(\frac{p}{1-p}) + log(1-p)\Bigg] + log({n \choose k }) \Bigg\}$

**Result:**

$\theta = log(\frac{p}{1-p})$

$q = n$

$c(\theta) = log({n \choose k })$


### Poisson

[ADD ME]

## 2. Identify the canonical link function for each of the models given above.

I JUST LOOKED THIS UP I'M NOT SURE IT'S CORRECT.

**Normal**

$\mu$

**Bernoulli**

$logit(\mu)$

**Binomial**

$logit(\mu)$

**Poisson**

$log(\mu)$

#### 3. Consider now the generalised linear model:

$t_{n}|x_{n} -> NdEF(\theta(x_{n},w),q\gamma_{n})$ with

$\theta(x_{n}, w) = (c')^{-1}(g^{-1}(\phi(x_{n})^{T} w)) =: f (\phi(x_{n})^{T} w)$


## 2. $R^{2}$ and deviance

**1. Show that for any linear regression model:**

$-2 log p(t|X, w_{MLE}, q_{MLE} ) = N log e^{T} e + const$

**where "const" does not depend on $M$ or $X$.**

We know that:

$-2logp(t|X,w,q) =-Nlogq+q(t-\phi w)^{T}(t-\phi w)+const$

Maximizing with respect to $w$ gives us:

$w_{mle} = (\phi^{T} \phi)^{-1}\phi^{T}t$

We plug this $w_{mle}$ back into the log likelihood to get the likelihood function given $w_{mle}$:

$-2logp(t|X,w_{mle},q) = -Nlog(q) + qe^{T}e$

Now, we can take the derivative wrt to $q$ to solve for $q_{mle}$ which gives us:

$q_{mle} = \Bigg(\frac{1}{N} e^{T}e\Bigg)^{-1}$

We use this to solve for the deviance of the maximum likelihood function:

$-2logp(t|X,w_{mle},q_{mle}) = -N log(q_{mle}) + q_{mle}e^{T}e$

$-N log(q_{mle}) + q_{mle}e^{T}e = -N log\Bigg((\frac{1}{N} e^{T}e)^{-1}\Bigg) + \Bigg(\frac{1}{N} e^{T}e\Bigg)^{-1}e^{T}e$

$= N log\Bigg((\frac{1}{N} e^{T}e)\Bigg) + N$

$= N[log(e^{T}e) - log(N)] + N$

$= Nlog(e^{T}e) - N(log(N) + 1)$

$= Nlog(e^{T}e) + const$
